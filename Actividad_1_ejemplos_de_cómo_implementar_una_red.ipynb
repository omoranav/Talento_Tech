{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Ejemplo de cómo implementar una red neuronal para\n",
        "#clasificación con (MLPClassifier) utilizando Sklearn\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "#Explorando los datos (opcional)\n",
        "type(iris)\n",
        "iris.keys()\n",
        "iris['data']\n",
        "iris['target']\n",
        "iris['target_names']\n",
        "iris['DESCR']\n",
        "iris['feature_names']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgZEeTZ81rT",
        "outputId": "62efc123-7f91-4f22-b5c9-558c8b92a6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entramiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear una instanci de MLPClassifier\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100),\n",
        "                        activation='relu',\n",
        "                        solver='adam',\n",
        "                        max_iter=100,\n",
        "                        random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "mlp_clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "G8tGjpI-85NR",
        "outputId": "cd505a0b-19ea-4093-99ac-63a941a68dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos predicciones en el conjunto de prueba\n",
        "\n",
        "Y_pred = mlp_clf.predict(X_test_scaled)\n",
        "print(y_test)\n",
        "print(Y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIDjUzlU9f_j",
        "outputId": "67f341ab-7085-4da8-d2d2-6fdf06d8d16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "[1 0 2 1 2 0 1 2 1 1 2 0 0 0 0 2 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, Y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEpLwEBQ9tml",
        "outputId": "bef7bd12-7870-4486-a1a7-9512b9a8e66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejemplo básico de cómo implementar una red\n",
        "#neuronal para regresión utilizando MLPRegressor de\n",
        "#Scikit-learn\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Cargar el conjunto de datos de California Housing\n",
        "housing = fetch_california_housing()\n",
        "X,y = housing.data, housing.target\n",
        "\n",
        "# Explorando los datos (Opcional)\n",
        "type(housing)\n",
        "housing.keys()\n",
        "housing['data']\n",
        "housing['target']\n",
        "housing['target_names']\n",
        "housing['DESCR']\n",
        "housing['feature_names']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WZLRcC79259",
        "outputId": "34761f5e-755e-4942-da74-36f0da1e1375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MedInc',\n",
              " 'HouseAge',\n",
              " 'AveRooms',\n",
              " 'AveBedrms',\n",
              " 'Population',\n",
              " 'AveOccup',\n",
              " 'Latitude',\n",
              " 'Longitude']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características para un mejor rendimiento del modelo\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear una instancia de MLPRegressor\n",
        "mlp_reg = MLPRegressor(hidden_layer_sizes=(100),\n",
        "                       activation='relu',\n",
        "                       solver='adam',\n",
        "                       max_iter=100,\n",
        "                       random_state=42)\n",
        "# Entrenar el modelo\n",
        "mlp_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realizar predicciones en el cojunto de prueba\n",
        "y_pred = mlp_reg.predict(X_test_scaled)\n",
        "\n",
        "# Calcular el error cuadrático medio (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Error cuadrático medio (MSE):\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-r5HJEV-7to",
        "outputId": "3a35292b-b13b-4e92-e64a-f813ca226731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error cuadrático medio (MSE): 0.32870115322611493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "X,Y = housing.data, housing.target\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scale = scaler.fit_transform(X)\n",
        "Y_scale = scaler.fit_transform(Y.reshape(-1, 1)).flatten()  # Flatten para asegurar una dimensión correcta\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y_scale, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir una función para crear el modelo\n",
        "def create_model(optimizer='adam', hidden_layer_sizes=(32, 32), activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_layer_sizes[0], activation=activation, input_shape=(X_train.shape[1],)))\n",
        "    for units in hidden_layer_sizes[1:]:\n",
        "        model.add(Dense(units, activation=activation))\n",
        "    model.add(Dense(1))  # Capa de salida para regresión lineal\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Función para evaluar el modelo con diferentes configuraciones\n",
        "def evaluate_model(X_train, Y_train, X_test, Y_test, optimizer, hidden_layer_sizes, activation, epochs):\n",
        "    model = create_model(optimizer=optimizer, hidden_layer_sizes=hidden_layer_sizes, activation=activation)\n",
        "    model.fit(X_train, Y_train, epochs=epochs, verbose=0)\n",
        "    Y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    # Calcular métricas de evaluación\n",
        "    accuracy = model.evaluate(X_test, Y_test)[1]\n",
        "    r2 = r2_score(Y_test, Y_pred)\n",
        "    mse = mean_squared_error(Y_test, Y_pred)\n",
        "\n",
        "    return optimizer, hidden_layer_sizes, activation, epochs, accuracy, r2, mse\n",
        "\n",
        "# Definir configuraciones a probar\n",
        "optimizers = ['adam', 'rmsprop', 'sgd']\n",
        "hidden_layer_sizes = [(32,), (64,), (32, 32), (64, 32)]\n",
        "activations = ['relu', 'sigmoid']\n",
        "epochs = [20, 30, 40]\n",
        "\n",
        "# Lista para almacenar resultados\n",
        "results = []\n",
        "\n",
        "# Iterar sobre todas las combinaciones de parámetros\n",
        "for opt in optimizers:\n",
        "    for hl_sizes in hidden_layer_sizes:\n",
        "        for act in activations:\n",
        "            for ep in epochs:\n",
        "                result = evaluate_model(X_train, Y_train, X_test, Y_test, opt, hl_sizes, act, ep)\n",
        "                results.append(result)\n",
        "\n",
        "# Crear un DataFrame para visualizar los resultados\n",
        "results_df = pd.DataFrame(results, columns=['Optimizer', 'Hidden Layer Sizes', 'Activation', 'Epochs', 'Accuracy', 'R2 Score', 'MSE'])\n",
        "results_df.sort_values(by='MSE', ascending=True, inplace=True)  # Ordenar por MSE ascendente o la métrica que prefieras\n",
        "\n",
        "# Mostrar tabla resumen\n",
        "print(\"Tabla Resumen de Resultados:\")\n",
        "print(results_df.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "# Guardar los resultados en un archivo CSV si deseas\n",
        "results_df.to_csv('results_summary.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLLbgqrhTOlY",
        "outputId": "0b188fef-a0ee-4a46-f784-cd1d6c3e0bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.0363\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.0368\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0390\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.0385\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.0383\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.0368\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.0397\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.0339\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.0378\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.0380\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.0397\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.0325\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.0346\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.0361\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.0375\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.0354\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.0363\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.0329\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.0320\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.0363\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.0397\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.0375\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.0325\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.0378\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0351\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.0402\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.0325\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.0349\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.0344\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.0346\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.0354\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.0317\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.0337\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.0334\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.0359\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.0346\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.0351\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.0329\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.0337\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.0344\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.0344\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.0354\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.0354\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 2.4225e-04\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.0048\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.0201\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.0342\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 2ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.0356\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.0034\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.0206\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.0274\n",
            "Tabla Resumen de Resultados:\n",
            "   Optimizer Hidden Layer Sizes Activation  Epochs  Accuracy  R2 Score  \\\n",
            "20      adam           (64, 32)       relu      40  0.039729  0.748432   \n",
            "14      adam           (32, 32)       relu      40  0.039729  0.727665   \n",
            "19      adam           (64, 32)       relu      30  0.038033  0.716795   \n",
            "44   rmsprop           (64, 32)       relu      40  0.040213  0.703946   \n",
            "8       adam              (64,)       relu      40  0.038517  0.702017   \n",
            "12      adam           (32, 32)       relu      20  0.038275  0.701181   \n",
            "18      adam           (64, 32)       relu      20  0.037791  0.698223   \n",
            "38   rmsprop           (32, 32)       relu      40  0.037548  0.691124   \n",
            "13      adam           (32, 32)       relu      30  0.036822  0.687871   \n",
            "7       adam              (64,)       relu      30  0.039002  0.680156   \n",
            "\n",
            "         MSE  \n",
            "20  0.014014  \n",
            "14  0.015171  \n",
            "19  0.015777  \n",
            "44  0.016493  \n",
            "8   0.016600  \n",
            "12  0.016647  \n",
            "18  0.016812  \n",
            "38  0.017207  \n",
            "13  0.017388  \n",
            "7   0.017818  \n"
          ]
        }
      ]
    }
  ]
}