{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhEnB4WXmts1",
        "outputId": "51131910-9ee0-4a43-df53-f317505f7aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download()"
      ],
      "metadata": {
        "id": "DeN2bBNInBv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División de una oración en palabras individuales.\n",
        "\n",
        "# Importar las bibliotecas necesarias\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Descargar los datos necesarios para la tokenización\n",
        "nltk.download('punkt')\n",
        "\n",
        "# División de una oración en palabras individuales\n",
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural en Python\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv1a6XZanMK_",
        "outputId": "02dc9cde-1224-43c1-da2d-23b791939a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'de', 'procesamiento', 'de', 'lenguaje', 'natural', 'en', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer a mano la función word_tokenize con un ciclo for\n",
        "\n",
        "def manual_word_tokenize_with_loop(text):\n",
        "    tokens = []  # Lista para almacenar los tokens finales\n",
        "    current_token = []  # Lista para acumular caracteres alfanuméricos que forman un token\n",
        "\n",
        "    for char in text:\n",
        "        if char.isalnum():\n",
        "            # Si el carácter es alfanumérico (letra o dígito), añadirlo al token actual\n",
        "            current_token.append(char)\n",
        "        else:\n",
        "            if current_token:\n",
        "                # Si el token actual no está vacío, unir los caracteres y añadir el token a la lista de tokens\n",
        "                tokens.append(''.join(current_token))\n",
        "                current_token = []  # Vaciar el token actual\n",
        "            if char.strip():  # Si el carácter no es un espacio, añadirlo como un token separado\n",
        "                tokens.append(char)\n",
        "\n",
        "    if current_token:\n",
        "        # Añadir cualquier token restante que no se haya añadido aún\n",
        "        tokens.append(''.join(current_token))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Ejemplos\n",
        "text = \"NLTK es una biblioteca de procesamiento de lenguaje natural en Python\"\n",
        "tokens = manual_word_tokenize_with_loop(text)\n",
        "print(tokens)\n",
        "\n",
        "text = \"Observación: División de una oración en palabras individuales \"\n",
        "tokens = manual_word_tokenize_with_loop(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "YB5suSzJrfbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3013f8c3-f146-4bb4-b7d6-0add9e8061a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'de', 'procesamiento', 'de', 'lenguaje', 'natural', 'en', 'Python']\n",
            "['Observación', ':', 'División', 'de', 'una', 'oración', 'en', 'palabras', 'individuales']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reducción de palabras a su forma base con NLTK\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "#words = ['trabanjando', 'trabajos', 'trabajador']\n",
        "words = ['running', 'plays', 'jumped']\n",
        "stemmer = PorterStemmer()\n",
        "stem = [stemmer.stem(word) for word in words]\n",
        "print(stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCbge6lpoG7q",
        "outputId": "75017b11-9c20-42f9-fa4e-d603d51c36d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'play', 'jump']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Etiquetado gramatical de palabras en una oración.\n",
        "\n",
        "# Importar las bibliotecas necesarias\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Descargar los datos necesarios para el etiquetado gramatical\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Etiquetado gramatical de palabras en una oración\n",
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural en Python\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged_words = pos_tag(tokens)\n",
        "print(tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYVcIqRxn6Df",
        "outputId": "a94c2685-9e10-4482-c88f-b217e1147893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NLTK', 'NNP'), ('es', 'CC'), ('una', 'JJ'), ('biblioteca', 'NN'), ('de', 'IN'), ('procesamiento', 'FW'), ('de', 'FW'), ('lenguaje', 'FW'), ('natural', 'JJ'), ('en', 'FW'), ('Python', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejemplo básico de clasificador de textos utilizando el clasificador\n",
        "#Naive Bayes de NLTK\n",
        "\n",
        "# 1. Importación de bibliotecas\n",
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "# Descargar el recurso 'punkt'\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# 2. Definición del cojunto de datos etiquetados\n",
        "\n",
        "#Ejemplo de conjunto de datos de textos etiquetados\n",
        "data = [\n",
        "    (\"I love this movie\", \"positive\"),\n",
        "    (\"This movie is terrible\", \"negative\"),\n",
        "    (\"This movie is great\" , \"positive\"),\n",
        "    (\"I dislike this movie\", \"negative\"),\n",
        "    (\"This film is amazing\", \"positive\"),\n",
        "    (\"I can't stand watching this movie\", \"negative\"),\n",
        "    (\"The acting in this movie is phenomenal\", \"positive\"),\n",
        "    (\"I regret wasting my time on this film\", \"negative\"),\n",
        "    (\"I thoroughly enjoyed this movie\", \"positive\"),\n",
        "    (\"This movie lacks depth and substance\", \"negative\"),\n",
        "    (\"The plot of this movie was captivating\", \"positive\"),\n",
        "    (\"I found the characters in this film to be very engaging\", \"positive\"),\n",
        "    (\"The special effects in this movie were impressive\", \"positive\"),\n",
        "    (\"The storyline was predictable and unoriginal\", \"negative\"),\n",
        "    (\"I was disappointed by the lack of character development\", \"negative\"),\n",
        "    (\"The cinematography in this film was stunning\", \"positive\"),\n",
        "    (\"The dialogue felt forced and unnatural\", \"negative\"),\n",
        "    (\"The pacing of the movie was too slow for my liking\" , \"negative\"),\n",
        "    (\"I was pleasantly surprised by how much I enjoyed this film\", \"positive\"),\n",
        "    (\"The ending left me feeling unsatisfied and confused\", \"negative\"),\n",
        "    (\"This movie exceeded my expectations\", \"positive\"),\n",
        "    (\"The performances by the actors were lackluster\", \"negative\")\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXygSIRhzqGU",
        "outputId": "7ca890ab-92a3-45c3-9cf6-1089a7c672c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preprocesamiento de datos\n",
        "\n",
        "#Preprocesamiento de datos: tokenización y extracción de características\n",
        "def preprocess_data(text):\n",
        "    preprocessed_data = []\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return {word: True for word in tokens}"
      ],
      "metadata": {
        "id": "yeDbZukh1dl1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Aplicación de preprocesamiento a los datos\n",
        "\n",
        "# Aplicamos el preprocesamiento a los datos\n",
        "featuresets = [(preprocess_data(text), label) for (text, label) in data]"
      ],
      "metadata": {
        "id": "T5BniTlg2Tgq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. División de datos\n",
        "\n",
        "#Dividimos los datos en conjunto de entrenamiento y prueba\n",
        "train_set, test_set = featuresets[:16], featuresets[16:]"
      ],
      "metadata": {
        "id": "IJZhew5O3Yls"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Entrenamiento del clasificador\n",
        "\n",
        "#Entrenamos un clasificador utilizando Naive Bayes\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "vhBfRu1I3mQA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluación del clasificador\n",
        "\n",
        "#Evaluamos el clasificador en el conjunto de prueba\n",
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEs3OzFD4I3_",
        "outputId": "8ee86b29-c162-4a4c-de5a-c88f96e81a7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Clasificación de un nuevo texto\n",
        "#Clasificamos un nuevo texto\n",
        "new_text = \"This movie is amazing\"\n",
        "new_text_features = preprocess_data(new_text)\n",
        "predicted_label = classifier.classify(new_text_features)\n",
        "print(\"Predicted_label:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxlM4GCb4TOF",
        "outputId": "f5a49d83-b502-44ff-d49f-ef5ed69e3c63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted_label: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preguntas de comprensión:\n",
        "\n",
        "1.\t¿Qué tarea realiza el código proporcionado?\n",
        "    \n",
        "    Rta. El código proporcionado clasifica un nuevo texto (new_text) utilizando un clasificador previamente entrenado\n",
        "\n",
        "\n",
        "2.\t¿Cuál es el propósito del preprocesamiento de datos en este contexto?\n",
        "    \n",
        "    Rta.El propósito del preprocesamiento de datos es transformar el texto bruto en una forma que pueda ser interpretada por el modelo de aprendizaje automático.\n",
        "\n",
        "\n",
        "3.\t¿Qué función de NLTK se utiliza para tokenizar el texto?\n",
        "    \n",
        "    Rta.La función de NLTK utilizada para tokenizar el texto es nltk.word_tokenize. Esta función divide el texto en palabras individuales o tokens.\n",
        "\n",
        "\n",
        "4.\t¿Cuál es el propósito de dividir los datos en conjuntos de entrenamiento y prueba?\n",
        "\n",
        "    Rta. El propósito de dividir los datos en conjuntos de entrenamiento y prueba es evaluar el rendimiento del modelo de clasificación. El conjunto de entrenamiento se utiliza para entrenar el modelo, mientras que el conjunto de prueba se utiliza para evaluar la precisión y generalización del modelo sobre datos no vistos.\n",
        "\n",
        "\n",
        "5.\t¿Qué algoritmo de clasificación se utiliza en este código?\n",
        "    \n",
        "    Rta. El algoritmo de clasificación utilizado es Naive Bayes (nltk.NaiveBayesClassifier).\n",
        "\n",
        "\n",
        "6.\t¿Cómo se evalúa la precisión del clasificador?\n",
        "    \n",
        "    Rta.La precisión del clasificador se evalúa utilizando el conjunto de prueba. Se calcula la proporción de predicciones correctas entre todas las predicciones realizadas en el conjunto de prueba. Esto se hace utilizando nltk.classify.accuracy.\n",
        "\n",
        "\n",
        "7.\t¿Qué se entiende por \"Accuracy\" en el contexto de evaluación del clasificador?\n",
        "    \n",
        "    Rta. \"Accuracy\" (precisión) en el contexto de evaluación del clasificador se refiere a la proporción de predicciones correctas realizadas por el clasificador sobre el conjunto de prueba. Es una métrica común para evaluar el rendimiento de un clasificador.\n",
        "\n",
        "\n",
        "8.\t¿Cuál es el resultado de la clasificación del nuevo texto \"This movie is amazing\"?\n",
        "\n",
        "    Rta. El resultado de la clasificación del nuevo texto \"This movie is amazing\" es la etiqueta predicha por el clasificador para este texto (Predicted_label: positive).\n",
        "\n",
        "\n",
        "Resumen\n",
        "\n",
        "El código clasifica un nuevo texto utilizando un clasificador entrenado, después de preprocesar el texto. La tokenización se realiza con nltk.word_tokenize. El preprocesamiento es esencial para transformar el texto en una representación adecuada para el clasificador. La división de datos en conjuntos de entrenamiento y prueba permite evaluar el rendimiento del clasificador. La precisión se calcula como la proporción de predicciones correctas en el conjunto de prueba. La etiqueta predicha para \"This movie is amazing\" es: positive.\n"
      ],
      "metadata": {
        "id": "K48U5_w77FyM"
      }
    }
  ]
}