{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhEnB4WXmts1",
        "outputId": "51131910-9ee0-4a43-df53-f317505f7aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download()"
      ],
      "metadata": {
        "id": "DeN2bBNInBv_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División de una oración en palabras individuales.\n",
        "\n",
        "# Importar las bibliotecas necesarias\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Descargar los datos necesarios para la tokenización\n",
        "nltk.download('punkt')\n",
        "\n",
        "# División de una oración en palabras individuales\n",
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural en Python\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv1a6XZanMK_",
        "outputId": "02dc9cde-1224-43c1-da2d-23b791939a09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'de', 'procesamiento', 'de', 'lenguaje', 'natural', 'en', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer a mano la función word_tokenize con un ciclo"
      ],
      "metadata": {
        "id": "YB5suSzJrfbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reducción de palabras a su forma base con NLTK\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "#words = ['trabanjando', 'trabajos', 'trabajador']\n",
        "words = ['running', 'plays', 'jumped']\n",
        "stemmer = PorterStemmer()\n",
        "stem = [stemmer.stem(word) for word in words]\n",
        "print(stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCbge6lpoG7q",
        "outputId": "75017b11-9c20-42f9-fa4e-d603d51c36d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'play', 'jump']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Etiquetado gramatical de palabras en una oración.\n",
        "\n",
        "# Importar las bibliotecas necesarias\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Descargar los datos necesarios para el etiquetado gramatical\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Etiquetado gramatical de palabras en una oración\n",
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural en Python\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged_words = pos_tag(tokens)\n",
        "print(tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYVcIqRxn6Df",
        "outputId": "a94c2685-9e10-4482-c88f-b217e1147893"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NLTK', 'NNP'), ('es', 'CC'), ('una', 'JJ'), ('biblioteca', 'NN'), ('de', 'IN'), ('procesamiento', 'FW'), ('de', 'FW'), ('lenguaje', 'FW'), ('natural', 'JJ'), ('en', 'FW'), ('Python', 'NN')]\n"
          ]
        }
      ]
    }
  ]
}